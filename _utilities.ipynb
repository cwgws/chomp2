{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHOMP v2\n",
    "__Misc. Utilities__\n",
    "\n",
    "__by Sean Gilleran__  \n",
    "__Last updated November 30__, __2021__  \n",
    "[https://github.com/seangilleran/chomp2](https://github.com/seangilleran/chomp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import en_core_web_sm\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "path = \"./corpus\"\n",
    "\n",
    "\n",
    "@Language.factory(\"language_detector\")\n",
    "def language_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "nlp.add_pipe(\"language_detector\", last=True)\n",
    "\n",
    "for file in [f for f in os.listdir(path) if f.endswith(f\".txt\")]:\n",
    "\n",
    "    with open(os.path.join(path, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    lang = nlp(text)._.language\n",
    "\n",
    "    if lang[\"language\"] != \"en\" or lang[\"score\"] < 0.7:\n",
    "        print(f\"{lang}: {file}\")\n",
    "\n",
    "    # Write results to CSV\n",
    "    with open(\"lang_check.csv\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{lang['language']},{lang['score']},{file}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PDF to TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
